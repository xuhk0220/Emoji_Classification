{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"3mRtbGgRcfP-","colab_type":"text"},"source":["There are two different kind of GPU in colab，K80 or T4. K80 has only 11G+ memory while T4 have 15G memory. K80 can't run this program. If you get a K80 GPU, you should close this page and wait until you get a T4 GPU.  \n","\n","The following cell is for you to check your GPU.\n"]},{"cell_type":"code","metadata":{"id":"Bqj5hOsdcli3","colab_type":"code","colab":{}},"source":["!nvidia-smi"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9KrHQUlhdKLh","colab_type":"text"},"source":["The following two cell is for the original Cifar10 dataset, copied from https://github.com/taki0112/SENet-Tensorflow "]},{"cell_type":"markdown","metadata":{"id":"-J9tIXERdZ_u","colab_type":"text"},"source":["The first:"]},{"cell_type":"code","metadata":{"id":"sS08XBs1dOog","colab_type":"code","colab":{}},"source":["# -*- coding:utf-8 -*-\n","\n","import os\n","import sys\n","import time\n","import pickle\n","import random\n","import numpy as np\n","\n","class_num = 10\n","image_size = 32\n","img_channels = 3\n","\n","\n","# ========================================================== #\n","# ├─ prepare_data()\n","#  ├─ download training data if not exist by download_data()\n","#  ├─ load data by load_data()\n","#  └─ shuffe and return data\n","# ========================================================== #\n","\n","\n","\n","def download_data():\n","    dirname = 'cifar-10-batches-py'\n","    origin = 'http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n","    fname = 'cifar-10-python.tar.gz'\n","    fpath = './' + dirname\n","\n","    download = False\n","    if os.path.exists(fpath) or os.path.isfile(fname):\n","        download = False\n","        print(\"DataSet aready exist!\")\n","    else:\n","        download = True\n","    if download:\n","        print('Downloading data from', origin)\n","        import urllib.request\n","        import tarfile\n","\n","        def reporthook(count, block_size, total_size):\n","            global start_time\n","            if count == 0:\n","                start_time = time.time()\n","                return\n","            duration = time.time() - start_time\n","            progress_size = int(count * block_size)\n","            speed = int(progress_size / (1024 * duration))\n","            percent = min(int(count * block_size * 100 / total_size), 100)\n","            sys.stdout.write(\"\\r...%d%%, %d MB, %d KB/s, %d seconds passed\" %\n","                             (percent, progress_size / (1024 * 1024), speed, duration))\n","            sys.stdout.flush()\n","\n","        urllib.request.urlretrieve(origin, fname, reporthook)\n","        print('Download finished. Start extract!', origin)\n","        if (fname.endswith(\"tar.gz\")):\n","            tar = tarfile.open(fname, \"r:gz\")\n","            tar.extractall()\n","            tar.close()\n","        elif (fname.endswith(\"tar\")):\n","            tar = tarfile.open(fname, \"r:\")\n","            tar.extractall()\n","            tar.close()\n","\n","\n","def unpickle(file):\n","    with open(file, 'rb') as fo:\n","        dict = pickle.load(fo, encoding='bytes')\n","    return dict\n","\n","\n","def load_data_one(file):\n","    batch = unpickle(file)\n","    data = batch[b'data']\n","    labels = batch[b'labels']\n","    print(\"Loading %s : %d.\" % (file, len(data)))\n","    return data, labels\n","\n","\n","def load_data(files, data_dir, label_count):\n","    global image_size, img_channels\n","    data, labels = load_data_one(data_dir + '/' + files[0])\n","    for f in files[1:]:\n","        data_n, labels_n = load_data_one(data_dir + '/' + f)\n","        data = np.append(data, data_n, axis=0)\n","        labels = np.append(labels, labels_n, axis=0)\n","    labels = np.array([[float(i == label) for i in range(label_count)] for label in labels])\n","    data = data.reshape([-1, img_channels, image_size, image_size])\n","    data = data.transpose([0, 2, 3, 1])\n","    return data, labels\n","\n","\n","def prepare_data():\n","    print(\"======Loading data======\")\n","    download_data()\n","    data_dir = './cifar-10-batches-py'\n","    image_dim = image_size * image_size * img_channels\n","    meta = unpickle(data_dir + '/batches.meta')\n","\n","    label_names = meta[b'label_names']\n","    label_count = len(label_names)\n","    train_files = ['data_batch_%d' % d for d in range(1, 6)]\n","    train_data, train_labels = load_data(train_files, data_dir, label_count)\n","    test_data, test_labels = load_data(['test_batch'], data_dir, label_count)\n","\n","    print(\"Train data:\", np.shape(train_data), np.shape(train_labels))\n","    print(\"Test data :\", np.shape(test_data), np.shape(test_labels))\n","    print(\"======Load finished======\")\n","\n","    print(\"======Shuffling data======\")\n","    indices = np.random.permutation(len(train_data))\n","    train_data = train_data[indices]\n","    train_labels = train_labels[indices]\n","    print(\"======Prepare Finished======\")\n","\n","    return train_data, train_labels, test_data, test_labels\n","\n","\n","# ========================================================== #\n","# ├─ _random_crop()\n","# ├─ _random_flip_leftright()\n","# ├─ data_augmentation()\n","# └─ color_preprocessing()\n","# ========================================================== #\n","\n","def _random_crop(batch, crop_shape, padding=None):\n","    oshape = np.shape(batch[0])\n","\n","    if padding:\n","        oshape = (oshape[0] + 2 * padding, oshape[1] + 2 * padding)\n","    new_batch = []\n","    npad = ((padding, padding), (padding, padding), (0, 0))\n","    for i in range(len(batch)):\n","        new_batch.append(batch[i])\n","        if padding:\n","            new_batch[i] = np.lib.pad(batch[i], pad_width=npad,\n","                                      mode='constant', constant_values=0)\n","        nh = random.randint(0, oshape[0] - crop_shape[0])\n","        nw = random.randint(0, oshape[1] - crop_shape[1])\n","        new_batch[i] = new_batch[i][nh:nh + crop_shape[0],\n","                       nw:nw + crop_shape[1]]\n","    return new_batch\n","\n","\n","def _random_flip_leftright(batch):\n","    for i in range(len(batch)):\n","        if bool(random.getrandbits(1)):\n","            batch[i] = np.fliplr(batch[i])\n","    return batch\n","\n","\n","def color_preprocessing(x_train, x_test):\n","    x_train = x_train.astype('float32')\n","    x_test = x_test.astype('float32')\n","    x_train[:, :, :, 0] = (x_train[:, :, :, 0] - np.mean(x_train[:, :, :, 0])) / np.std(x_train[:, :, :, 0])\n","    x_train[:, :, :, 1] = (x_train[:, :, :, 1] - np.mean(x_train[:, :, :, 1])) / np.std(x_train[:, :, :, 1])\n","    x_train[:, :, :, 2] = (x_train[:, :, :, 2] - np.mean(x_train[:, :, :, 2])) / np.std(x_train[:, :, :, 2])\n","\n","    x_test[:, :, :, 0] = (x_test[:, :, :, 0] - np.mean(x_test[:, :, :, 0])) / np.std(x_test[:, :, :, 0])\n","    x_test[:, :, :, 1] = (x_test[:, :, :, 1] - np.mean(x_test[:, :, :, 1])) / np.std(x_test[:, :, :, 1])\n","    x_test[:, :, :, 2] = (x_test[:, :, :, 2] - np.mean(x_test[:, :, :, 2])) / np.std(x_test[:, :, :, 2])\n","\n","    return x_train, x_test\n","\n","\n","def data_augmentation(batch):\n","    batch = _random_flip_leftright(batch)\n","    batch = _random_crop(batch, [32, 32], 4)\n","    return batch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NIf3WXdsdi1J","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tflearn.layers.conv import global_avg_pool\n","from tensorflow.contrib.layers import batch_norm, flatten\n","from tensorflow.contrib.framework import arg_scope\n","import numpy as np\n","\n","weight_decay = 0.0005\n","momentum = 0.9\n","\n","init_learning_rate = 0.1\n","cardinality = 8 # how many split ?\n","blocks = 3 # res_block ! (split + transition)\n","depth = 64 # out channel\n","\n","\"\"\"\n","So, the total number of layers is (3*blokcs)*residual_layer_num + 2\n","because, blocks = split(conv 2) + transition(conv 1) = 3 layer\n","and, first conv layer 1, last dense layer 1\n","thus, total number of layers = (3*blocks)*residual_layer_num + 2\n","\"\"\"\n","\n","reduction_ratio = 4\n","\n","batch_size = 128\n","\n","iteration = 391\n","# 128 * 391 ~ 50,000\n","\n","test_iteration = 10\n","\n","total_epochs = 100\n","\n","def conv_layer(input, filter, kernel, stride, padding='SAME', layer_name=\"conv\"):\n","    with tf.name_scope(layer_name):\n","        network = tf.layers.conv2d(inputs=input, use_bias=False, filters=filter, kernel_size=kernel, strides=stride, padding=padding)\n","        return network\n","\n","def Global_Average_Pooling(x):\n","    return global_avg_pool(x, name='Global_avg_pooling')\n","\n","def Average_pooling(x, pool_size=[2,2], stride=2, padding='SAME'):\n","    return tf.layers.average_pooling2d(inputs=x, pool_size=pool_size, strides=stride, padding=padding)\n","\n","def Batch_Normalization(x, training, scope):\n","    with arg_scope([batch_norm],\n","                   scope=scope,\n","                   updates_collections=None,\n","                   decay=0.9,\n","                   center=True,\n","                   scale=True,\n","                   zero_debias_moving_mean=True) :\n","        return tf.cond(training,\n","                       lambda : batch_norm(inputs=x, is_training=training, reuse=None),\n","                       lambda : batch_norm(inputs=x, is_training=training, reuse=True))\n","\n","def Relu(x):\n","    return tf.nn.relu(x)\n","\n","def Sigmoid(x) :\n","    return tf.nn.sigmoid(x)\n","\n","def Concatenation(layers) :\n","    return tf.concat(layers, axis=3)\n","\n","def Fully_connected(x, units=class_num, layer_name='fully_connected') :\n","    with tf.name_scope(layer_name) :\n","        return tf.layers.dense(inputs=x, use_bias=False, units=units)\n","\n","def Evaluate(sess):\n","    test_acc = 0.0\n","    test_loss = 0.0\n","    test_pre_index = 0\n","    add = 1000\n","\n","    for it in range(test_iteration):\n","        test_batch_x = test_x[test_pre_index: test_pre_index + add]\n","        test_batch_y = test_y[test_pre_index: test_pre_index + add]\n","        test_pre_index = test_pre_index + add\n","\n","        test_feed_dict = {\n","            x: test_batch_x,\n","            label: test_batch_y,\n","            learning_rate: epoch_learning_rate,\n","            training_flag: False\n","        }\n","\n","        loss_, acc_ = sess.run([cost, accuracy], feed_dict=test_feed_dict)\n","\n","        test_loss += loss_\n","        test_acc += acc_\n","\n","    test_loss /= test_iteration # average loss\n","    test_acc /= test_iteration # average accuracy\n","\n","    summary = tf.Summary(value=[tf.Summary.Value(tag='test_loss', simple_value=test_loss),\n","                                tf.Summary.Value(tag='test_accuracy', simple_value=test_acc)])\n","\n","    return test_acc, test_loss, summary\n","\n","class SE_ResNeXt():\n","    def __init__(self, x, training):\n","        self.training = training\n","        self.model = self.Build_SEnet(x)\n","\n","    def first_layer(self, x, scope):\n","        with tf.name_scope(scope) :\n","            x = conv_layer(x, filter=64, kernel=[3, 3], stride=1, layer_name=scope+'_conv1')\n","            x = Batch_Normalization(x, training=self.training, scope=scope+'_batch1')\n","            x = Relu(x)\n","\n","            return x\n","\n","    def transform_layer(self, x, stride, scope):\n","        with tf.name_scope(scope) :\n","            x = conv_layer(x, filter=depth, kernel=[1,1], stride=1, layer_name=scope+'_conv1')\n","            x = Batch_Normalization(x, training=self.training, scope=scope+'_batch1')\n","            x = Relu(x)\n","\n","            x = conv_layer(x, filter=depth, kernel=[3,3], stride=stride, layer_name=scope+'_conv2')\n","            x = Batch_Normalization(x, training=self.training, scope=scope+'_batch2')\n","            x = Relu(x)\n","            return x\n","\n","    def transition_layer(self, x, out_dim, scope):\n","        with tf.name_scope(scope):\n","            x = conv_layer(x, filter=out_dim, kernel=[1,1], stride=1, layer_name=scope+'_conv1')\n","            x = Batch_Normalization(x, training=self.training, scope=scope+'_batch1')\n","            # x = Relu(x)\n","\n","            return x\n","\n","    def split_layer(self, input_x, stride, layer_name):\n","        with tf.name_scope(layer_name) :\n","            layers_split = list()\n","            for i in range(cardinality) :\n","                splits = self.transform_layer(input_x, stride=stride, scope=layer_name + '_splitN_' + str(i))\n","                layers_split.append(splits)\n","\n","            return Concatenation(layers_split)\n","\n","    def squeeze_excitation_layer(self, input_x, out_dim, ratio, layer_name):\n","        with tf.name_scope(layer_name) :\n","\n","\n","            squeeze = Global_Average_Pooling(input_x)\n","\n","            excitation = Fully_connected(squeeze, units=out_dim / ratio, layer_name=layer_name+'_fully_connected1')\n","            excitation = Relu(excitation)\n","            excitation = Fully_connected(excitation, units=out_dim, layer_name=layer_name+'_fully_connected2')\n","            excitation = Sigmoid(excitation)\n","\n","            excitation = tf.reshape(excitation, [-1,1,1,out_dim])\n","            scale = input_x * excitation\n","\n","            return scale\n","\n","    def residual_layer(self, input_x, out_dim, layer_num, res_block=blocks):\n","        # split + transform(bottleneck) + transition + merge\n","        # input_dim = input_x.get_shape().as_list()[-1]\n","\n","        for i in range(res_block):\n","            input_dim = int(np.shape(input_x)[-1])\n","\n","            if input_dim * 2 == out_dim:\n","                flag = True\n","                stride = 2\n","                channel = input_dim // 2\n","            else:\n","                flag = False\n","                stride = 1\n","\n","            x = self.split_layer(input_x, stride=stride, layer_name='split_layer_'+layer_num+'_'+str(i))\n","            x = self.transition_layer(x, out_dim=out_dim, scope='trans_layer_'+layer_num+'_'+str(i))\n","            x = self.squeeze_excitation_layer(x, out_dim=out_dim, ratio=reduction_ratio, layer_name='squeeze_layer_'+layer_num+'_'+str(i))\n","\n","            if flag is True :\n","                pad_input_x = Average_pooling(input_x)\n","                pad_input_x = tf.pad(pad_input_x, [[0, 0], [0, 0], [0, 0], [channel, channel]]) # [?, height, width, channel]\n","            else :\n","                pad_input_x = input_x\n","\n","            input_x = Relu(x + pad_input_x)\n","\n","        return input_x\n","\n","\n","    def Build_SEnet(self, input_x):\n","        # only cifar10 architecture\n","\n","        input_x = self.first_layer(input_x, scope='first_layer')\n","\n","        x = self.residual_layer(input_x, out_dim=64, layer_num='1')\n","        x = self.residual_layer(x, out_dim=128, layer_num='2')\n","        x = self.residual_layer(x, out_dim=256, layer_num='3')\n","\n","        x = Global_Average_Pooling(x)\n","        x = flatten(x)\n","\n","        x = Fully_connected(x, layer_name='final_fully_connected')\n","        return x\n","\n","\n","train_x, train_y, test_x, test_y = prepare_data()\n","train_x, test_x = color_preprocessing(train_x, test_x)\n","\n","\n","# image_size = 32, img_channels = 3, class_num = 10 in cifar10\n","x = tf.placeholder(tf.float32, shape=[None, image_size, image_size, img_channels])\n","label = tf.placeholder(tf.float32, shape=[None, class_num])\n","\n","training_flag = tf.placeholder(tf.bool)\n","\n","\n","learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n","\n","logits = SE_ResNeXt(x, training=training_flag).model\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=label, logits=logits))\n","\n","l2_loss = tf.add_n([tf.nn.l2_loss(var) for var in tf.trainable_variables()])\n","optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=momentum, use_nesterov=True)\n","train = optimizer.minimize(cost + l2_loss * weight_decay)\n","\n","correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(label, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","\n","saver = tf.train.Saver(tf.global_variables())\n","\n","with tf.Session() as sess:\n","# with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess :\n","    ckpt = tf.train.get_checkpoint_state('./Emoji_Classification')\n","    if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n","        saver.restore(sess, ckpt.model_checkpoint_path)\n","    else:\n","        sess.run(tf.global_variables_initializer())\n","\n","    summary_writer = tf.summary.FileWriter('./logs', sess.graph)\n","\n","    epoch_learning_rate = init_learning_rate\n","    for epoch in range(1, total_epochs + 1):\n","        if epoch % 30 == 0 :\n","            epoch_learning_rate = epoch_learning_rate / 10\n","\n","        pre_index = 0\n","        train_acc = 0.0\n","        train_loss = 0.0\n","\n","        for step in range(1, iteration + 1):\n","            if pre_index + batch_size < 50000:\n","                batch_x = train_x[pre_index: pre_index + batch_size]\n","                batch_y = train_y[pre_index: pre_index + batch_size]\n","            else:\n","                batch_x = train_x[pre_index:]\n","                batch_y = train_y[pre_index:]\n","\n","            batch_x = data_augmentation(batch_x)\n","\n","            train_feed_dict = {\n","                x: batch_x,\n","                label: batch_y,\n","                learning_rate: epoch_learning_rate,\n","                training_flag: True\n","            }\n","\n","            _, batch_loss = sess.run([train, cost], feed_dict=train_feed_dict)\n","            batch_acc = accuracy.eval(feed_dict=train_feed_dict)\n","\n","            train_loss += batch_loss\n","            train_acc += batch_acc\n","            pre_index += batch_size\n","\n","\n","        train_loss /= iteration # average loss\n","        train_acc /= iteration # average accuracy\n","\n","        train_summary = tf.Summary(value=[tf.Summary.Value(tag='train_loss', simple_value=train_loss),\n","                                          tf.Summary.Value(tag='train_accuracy', simple_value=train_acc)])\n","\n","        test_acc, test_loss, test_summary = Evaluate(sess)\n","\n","        summary_writer.add_summary(summary=train_summary, global_step=epoch)\n","        summary_writer.add_summary(summary=test_summary, global_step=epoch)\n","        summary_writer.flush()\n","\n","        line = \"epoch: %d/%d, train_loss: %.4f, train_acc: %.4f, test_loss: %.4f, test_acc: %.4f \\n\" % (\n","            epoch, total_epochs, train_loss, train_acc, test_loss, test_acc)\n","        print(line)\n","\n","        with open('logs.txt', 'a') as f:\n","            f.write(line)\n","\n","        saver.save(sess=sess, save_path='./Emoji_Classification/ResNeXt.ckpt')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZdrZEnmOayoF","colab_type":"text"},"source":["The following cells are written or modified by Xuhk, published on https://github.com/xuhk0220/Emoji_Classification\n"," \n","You can download my model on https://drive.google.com/open?id=1zDwXJxuLPkODAG99Yvd7VLCqihPTKkUS"]},{"cell_type":"code","metadata":{"id":"ep2G44TRbNYx","colab_type":"code","colab":{}},"source":["!wget https://github.com/xuhk0220/Emoji_Classification/raw/master/ok.zip\n","!unzip ok.zip\n","!ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgqS1xaXbX4J","colab_type":"code","colab":{}},"source":["import numpy as np\n","import cv2 as cv\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder\n","import os\n","import random\n","class_num = 10\n","image_size = 32\n","img_channels = 3\n","\n","\n","def get_rgb_vector(imgPath):\n","\timg = cv.imread(imgPath)\n","\t# img=cv.resize(img,(32,32))\n","\tB, G, R = cv.split(img)\n","\tB = np.reshape(B, (1, 1024))\n","\tG = np.reshape(G, (1, 1024))\n","\tR = np.reshape(R, (1, 1024))\n","\tvector = np.concatenate((R, G, B), axis=1)\n","\treturn vector\n","\n","\n","def prepare_data():\n","\tdir='./ok'\n","\tlabels=[]\n","\tdata=[]\n","\tfor i,imgpath in enumerate(os.listdir(dir)):\n","\t\t# if i==0:\n","\t\t# \tdata=get_rgb_vector(dir+'/'+imgpath)\n","\t\t# else:\n","\t\t# \tdata = np.concatenate((data,get_rgb_vector(dir+'/'+imgpath)), axis=0)\n","\n","\t\tdata.append(cv.imread(dir+'/'+imgpath))\n","\t\tlabels.append(int(imgpath[:2]))\n","\tlabels=np.array(labels)\n","\tdata=np.array(data)\n","\n","\ttrain_data, test_data, train_labels, test_labels = train_test_split(data,labels,test_size=0.2)\n","\n","\tonehot=OneHotEncoder()\n","\ttrain_labels=onehot.fit_transform(train_labels.reshape(-1,1)).toarray()\n","\ttest_labels=onehot.fit_transform(test_labels.reshape(-1,1)).toarray()\n","\n","\treturn train_data, train_labels, test_data, test_labels\n","\n","\n","def _random_crop(batch, crop_shape, padding=None):\n","    oshape = np.shape(batch[0])\n","\n","    if padding:\n","        oshape = (oshape[0] + 2 * padding, oshape[1] + 2 * padding)\n","    new_batch = []\n","    npad = ((padding, padding), (padding, padding), (0, 0))\n","    for i in range(len(batch)):\n","        new_batch.append(batch[i])\n","        if padding:\n","            new_batch[i] = np.lib.pad(batch[i], pad_width=npad,\n","                                      mode='constant', constant_values=0)\n","        nh = random.randint(0, oshape[0] - crop_shape[0])\n","        nw = random.randint(0, oshape[1] - crop_shape[1])\n","        new_batch[i] = new_batch[i][nh:nh + crop_shape[0],\n","                       nw:nw + crop_shape[1]]\n","    return new_batch\n","\n","\n","def _random_flip_leftright(batch):\n","    for i in range(len(batch)):\n","        if bool(random.getrandbits(1)):\n","            batch[i] = np.fliplr(batch[i])\n","    return batch\n","\n","\n","def color_preprocessing(x_train, x_test):\n","    x_train = x_train.astype('float32')\n","    x_test = x_test.astype('float32')\n","    x_train[:, :, :, 0] = (x_train[:, :, :, 0] - np.mean(x_train[:, :, :, 0])) / np.std(x_train[:, :, :, 0])\n","    x_train[:, :, :, 1] = (x_train[:, :, :, 1] - np.mean(x_train[:, :, :, 1])) / np.std(x_train[:, :, :, 1])\n","    x_train[:, :, :, 2] = (x_train[:, :, :, 2] - np.mean(x_train[:, :, :, 2])) / np.std(x_train[:, :, :, 2])\n","\n","    x_test[:, :, :, 0] = (x_test[:, :, :, 0] - np.mean(x_test[:, :, :, 0])) / np.std(x_test[:, :, :, 0])\n","    x_test[:, :, :, 1] = (x_test[:, :, :, 1] - np.mean(x_test[:, :, :, 1])) / np.std(x_test[:, :, :, 1])\n","    x_test[:, :, :, 2] = (x_test[:, :, :, 2] - np.mean(x_test[:, :, :, 2])) / np.std(x_test[:, :, :, 2])\n","\n","    return x_train, x_test\n","\n","\n","def data_augmentation(batch):\n","    batch = _random_flip_leftright(batch)\n","    batch = _random_crop(batch, [32, 32], 4)\n","    return batch"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vtn6_keybbaA","colab_type":"text"},"source":["The following cell is modified from SE_ResNeXt.py in order to fit the dataset by myself.\n","\n","(The meme picture)-v1.3"]},{"cell_type":"code","metadata":{"id":"ZJ4QT8tubdqO","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tflearn.layers.conv import global_avg_pool\n","from tensorflow.contrib.layers import batch_norm, flatten\n","from tensorflow.contrib.framework import arg_scope\n","import keras.layers\n","import numpy as np\n","\n","weight_decay = 0.0005\n","momentum = 0.9\n","\n","init_learning_rate = 0.1\n","cardinality = 8 # how many split ?\n","blocks = 3 # res_block ! (split + transition)\n","depth = 64 # out channel\n","\n","\"\"\"\n","So, the total number of layers is (3*blokcs)*residual_layer_num + 2\n","because, blocks = split(conv 2) + transition(conv 1) = 3 layer\n","and, first conv layer 1, last dense layer 1\n","thus, total number of layers = (3*blocks)*residual_layer_num + 2\n","\"\"\"\n","\n","reduction_ratio = 4\n","class_num=10\n","batch_size = 128\n","\n","# iteration = 391\n","# 128 * 391 ~ 50,000\n","\n","iteration=36\n","# 128*36~4608\n","\n","test_iteration = 10\n","\n","total_epochs = 100\n","\n","def conv_layer(input, filter, kernel, stride, padding='SAME', layer_name=\"conv\"):\n","    with tf.name_scope(layer_name):\n","        network = tf.layers.conv2d(inputs=input, use_bias=False, filters=filter, kernel_size=kernel, strides=stride, padding=padding)\n","        return network\n","\n","def Global_Average_Pooling(x):\n","    return global_avg_pool(x, name='Global_avg_pooling')\n","\n","def Average_pooling(x, pool_size=[2,2], stride=2, padding='SAME'):\n","    return tf.layers.average_pooling2d(inputs=x, pool_size=pool_size, strides=stride, padding=padding)\n","\n","def Batch_Normalization(x, training, scope):\n","    with arg_scope([batch_norm],\n","                   scope=scope,\n","                   updates_collections=None,\n","                   decay=0.9,\n","                   center=True,\n","                   scale=True,\n","                   zero_debias_moving_mean=True) :\n","        return tf.cond(training,\n","                       lambda : batch_norm(inputs=x, is_training=training, reuse=None),\n","                       lambda : batch_norm(inputs=x, is_training=training, reuse=True))\n","\n","def Relu(x):\n","    return tf.nn.relu(x)\n","\n","def Sigmoid(x) :\n","    return tf.nn.sigmoid(x)\n","\n","def Concatenation(layers) :\n","    return tf.concat(layers, axis=3)\n","\n","def Fully_connected(x, units=class_num, layer_name='fully_connected') :\n","    with tf.name_scope(layer_name) :\n","        return tf.layers.dense(inputs=x, use_bias=False, units=units)\n","\n","def Evaluate(sess):\n","    test_acc = 0.0\n","    test_loss = 0.0\n","    test_pre_index = 0\n","    add = int(len(test_x)/test_iteration)\n","\n","    for it in range(test_iteration):\n","        test_batch_x = test_x[test_pre_index: test_pre_index + add]\n","        test_batch_y = test_y[test_pre_index: test_pre_index + add]\n","        test_pre_index = test_pre_index + add\n","\n","        test_feed_dict = {\n","            x: test_batch_x,\n","            label: test_batch_y,\n","            learning_rate: epoch_learning_rate,\n","            training_flag: False\n","        }\n","\n","        loss_, acc_ = sess.run([cost, accuracy], feed_dict=test_feed_dict)\n","\n","        test_loss += loss_\n","        test_acc += acc_\n","\n","    test_loss /= test_iteration # average loss\n","    test_acc /= test_iteration # average accuracy\n","\n","    summary = tf.Summary(value=[tf.Summary.Value(tag='test_loss', simple_value=test_loss),\n","                                tf.Summary.Value(tag='test_accuracy', simple_value=test_acc)])\n","\n","    return test_acc, test_loss, summary\n","\n","class SE_ResNeXt():\n","    def __init__(self, x, training):\n","        self.training = training\n","        self.model = self.Build_SEnet(x)\n","\n","    def first_layer(self, x, scope):\n","        with tf.name_scope(scope) :\n","            x = conv_layer(x, filter=64, kernel=[3, 3], stride=1, layer_name=scope+'_conv1')\n","            x = Batch_Normalization(x, training=self.training, scope=scope+'_batch1')\n","            x = Relu(x)\n","\n","            return x\n","\n","    def transform_layer(self, x, stride, scope):\n","        with tf.name_scope(scope) :\n","            x = conv_layer(x, filter=depth, kernel=[1,1], stride=1, layer_name=scope+'_conv1')\n","            x = Batch_Normalization(x, training=self.training, scope=scope+'_batch1')\n","            x = Relu(x)\n","\n","            x = conv_layer(x, filter=depth, kernel=[3,3], stride=stride, layer_name=scope+'_conv2')\n","            x = Batch_Normalization(x, training=self.training, scope=scope+'_batch2')\n","            x = Relu(x)\n","            return x\n","\n","    def transition_layer(self, x, out_dim, scope):\n","        with tf.name_scope(scope):\n","            x = conv_layer(x, filter=out_dim, kernel=[1,1], stride=1, layer_name=scope+'_conv1')\n","            x = Batch_Normalization(x, training=self.training, scope=scope+'_batch1')\n","            # x = Relu(x)\n","\n","            return x\n","\n","    def split_layer(self, input_x, stride, layer_name):\n","        with tf.name_scope(layer_name) :\n","            layers_split = list()\n","            for i in range(cardinality) :\n","                splits = self.transform_layer(input_x, stride=stride, scope=layer_name + '_splitN_' + str(i))\n","                layers_split.append(splits)\n","\n","            return Concatenation(layers_split)\n","\n","    def squeeze_excitation_layer(self, input_x, out_dim, ratio, layer_name):\n","        with tf.name_scope(layer_name) :\n","\n","\n","            squeeze = Global_Average_Pooling(input_x)\n","\n","            excitation = Fully_connected(squeeze, units=out_dim / ratio, layer_name=layer_name+'_fully_connected1')\n","            excitation = Relu(excitation)\n","            excitation = Fully_connected(excitation, units=out_dim, layer_name=layer_name+'_fully_connected2')\n","            excitation = Sigmoid(excitation)\n","\n","            excitation = tf.reshape(excitation, [-1,1,1,out_dim])\n","            scale = input_x * excitation\n","\n","            return scale\n","\n","    def residual_layer(self, input_x, out_dim, layer_num, res_block=blocks):\n","        # split + transform(bottleneck) + transition + merge\n","        # input_dim = input_x.get_shape().as_list()[-1]\n","\n","        for i in range(res_block):\n","            input_dim = int(np.shape(input_x)[-1])\n","\n","            if input_dim * 2 == out_dim:\n","                flag = True\n","                stride = 2\n","                channel = input_dim // 2\n","            else:\n","                flag = False\n","                stride = 1\n","\n","            x = self.split_layer(input_x, stride=stride, layer_name='split_layer_'+layer_num+'_'+str(i))\n","            x = self.transition_layer(x, out_dim=out_dim, scope='trans_layer_'+layer_num+'_'+str(i))\n","            x = self.squeeze_excitation_layer(x, out_dim=out_dim, ratio=reduction_ratio, layer_name='squeeze_layer_'+layer_num+'_'+str(i))\n","\n","            if flag is True :\n","                pad_input_x = Average_pooling(input_x)\n","                pad_input_x = tf.pad(pad_input_x, [[0, 0], [0, 0], [0, 0], [channel, channel]]) # [?, height, width, channel]\n","            else :\n","                pad_input_x = input_x\n","\n","            input_x = Relu(x + pad_input_x)\n","\n","        return input_x\n","\n","\n","    def Build_SEnet(self, input_x):\n","        # only cifar10 architecture\n","\n","        input_x = self.first_layer(input_x, scope='first_layer')\n","\n","        x = self.residual_layer(input_x, out_dim=64, layer_num='1')\n","        x = self.residual_layer(x, out_dim=128, layer_num='2')\n","        x = self.residual_layer(x, out_dim=256, layer_num='3')\n","\n","        x = Global_Average_Pooling(x)\n","        x = flatten(x)\n","\n","        x = Fully_connected(x, layer_name='final_fully_connected')\n","        return x\n","\n","\n","train_x, train_y, test_x, test_y = prepare_data()\n","train_x, test_x = color_preprocessing(train_x, test_x)\n","\n","\n","# image_size = 32, img_channels = 3, class_num = 10 in cifar10\n","x = tf.placeholder(tf.float32, shape=[None, image_size, image_size, img_channels])\n","label = tf.placeholder(tf.float32, shape=[None, class_num])\n","\n","training_flag = tf.placeholder(tf.bool)\n","\n","\n","learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n","\n","logits = SE_ResNeXt(x, training=training_flag).model\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=label, logits=logits))\n","\n","l2_loss = tf.add_n([tf.nn.l2_loss(var) for var in tf.trainable_variables()])\n","optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=momentum, use_nesterov=True)\n","train = optimizer.minimize(cost + l2_loss * weight_decay)\n","\n","correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(label, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","\n","saver = tf.train.Saver(tf.global_variables())\n","\n","# with tf.Session() as sess:\n","with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess :\n","    ckpt = tf.train.get_checkpoint_state('./model')\n","    if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n","        saver.restore(sess, ckpt.model_checkpoint_path)\n","    else:\n","        sess.run(tf.global_variables_initializer())\n","\n","    summary_writer = tf.summary.FileWriter('./logs', sess.graph)\n","\n","    epoch_learning_rate = init_learning_rate\n","    for epoch in range(1, total_epochs + 1):\n","        if epoch % 30 == 0 :\n","            epoch_learning_rate = epoch_learning_rate / 10\n","\n","        pre_index = 0\n","        train_acc = 0.0\n","        train_loss = 0.0\n","\n","        for step in range(1, iteration + 1):\n","            if pre_index + batch_size < 4586:\n","                batch_x = train_x[pre_index: pre_index + batch_size]\n","                batch_y = train_y[pre_index: pre_index + batch_size]\n","            else:\n","                batch_x = train_x[pre_index:]\n","                batch_y = train_y[pre_index:]\n","\n","            batch_x = data_augmentation(batch_x)\n","\n","            train_feed_dict = {\n","                x: batch_x,\n","                label: batch_y,\n","                learning_rate: epoch_learning_rate,\n","                training_flag: True\n","            }\n","\n","            _, batch_loss = sess.run([train, cost], feed_dict=train_feed_dict)\n","            batch_acc = accuracy.eval(feed_dict=train_feed_dict)\n","\n","            train_loss += batch_loss\n","            train_acc += batch_acc\n","            pre_index += batch_size\n","\n","\n","        train_loss /= iteration # average loss\n","        train_acc /= iteration # average accuracy\n","\n","        train_summary = tf.Summary(value=[tf.Summary.Value(tag='train_loss', simple_value=train_loss),\n","                                          tf.Summary.Value(tag='train_accuracy', simple_value=train_acc)])\n","\n","        test_acc, test_loss, test_summary = Evaluate(sess)\n","\n","        summary_writer.add_summary(summary=train_summary, global_step=epoch)\n","        summary_writer.add_summary(summary=test_summary, global_step=epoch)\n","        summary_writer.flush()\n","\n","        line = \"epoch: %d/%d, train_loss: %.4f, train_acc: %.4f, test_loss: %.4f, test_acc: %.4f \\n\" % (\n","            epoch, total_epochs, train_loss, train_acc, test_loss, test_acc)\n","        print(line)\n","\n","        with open('logs.txt', 'a') as f:\n","            f.write(line)\n","\n","        saver.save(sess=sess, save_path='./model/ResNeXt.ckpt')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zc82h88LcDLt","colab_type":"text"},"source":["Then I will try to modify the model. First, I want to  add a residual_layer.(v1.4)\n","\n","\n","\n","```\n","# Difference\n","\n","    def Build_SEnet(self, input_x):\n","        # only cifar10 architecture\n","\n","        input_x = self.first_layer(input_x, scope='first_layer')\n","\n","        x = self.residual_layer(input_x, out_dim=64, layer_num='1')\n","        x = self.residual_layer(x, out_dim=128, layer_num='2')\n","        x = self.residual_layer(x, out_dim=256, layer_num='3')\n","        x = self.residual_layer(x, out_dim=512, layer_num='4')\n","        \n","        x = Global_Average_Pooling(x)\n","        x = flatten(x)\n","\n","        x = Fully_connected(x, layer_name='final_fully_connected')\n","        return x\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"1hRYO73gcFod","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tflearn.layers.conv import global_avg_pool\n","from tensorflow.contrib.layers import batch_norm, flatten\n","from tensorflow.contrib.framework import arg_scope\n","import keras.layers\n","import numpy as np\n","\n","weight_decay = 0.0005\n","momentum = 0.9\n","\n","init_learning_rate = 0.1\n","cardinality = 8 # how many split ?\n","blocks = 3 # res_block ! (split + transition)\n","depth = 64 # out channel\n","\n","\"\"\"\n","So, the total number of layers is (3*blokcs)*residual_layer_num + 2\n","because, blocks = split(conv 2) + transition(conv 1) = 3 layer\n","and, first conv layer 1, last dense layer 1\n","thus, total number of layers = (3*blocks)*residual_layer_num + 2\n","\"\"\"\n","\n","reduction_ratio = 4\n","class_num=10\n","batch_size = 128\n","\n","# iteration = 391\n","# 128 * 391 ~ 50,000\n","\n","iteration=36\n","# 128*36~4608\n","\n","test_iteration = 10\n","\n","total_epochs = 100\n","\n","def conv_layer(input, filter, kernel, stride, padding='SAME', layer_name=\"conv\"):\n","    with tf.name_scope(layer_name):\n","        network = tf.layers.conv2d(inputs=input, use_bias=False, filters=filter, kernel_size=kernel, strides=stride, padding=padding)\n","        return network\n","\n","def Global_Average_Pooling(x):\n","    return global_avg_pool(x, name='Global_avg_pooling')\n","\n","def Average_pooling(x, pool_size=[2,2], stride=2, padding='SAME'):\n","    return tf.layers.average_pooling2d(inputs=x, pool_size=pool_size, strides=stride, padding=padding)\n","\n","def Batch_Normalization(x, training, scope):\n","    with arg_scope([batch_norm],\n","                   scope=scope,\n","                   updates_collections=None,\n","                   decay=0.9,\n","                   center=True,\n","                   scale=True,\n","                   zero_debias_moving_mean=True) :\n","        return tf.cond(training,\n","                       lambda : batch_norm(inputs=x, is_training=training, reuse=None),\n","                       lambda : batch_norm(inputs=x, is_training=training, reuse=True))\n","\n","def Relu(x):\n","    return tf.nn.relu(x)\n","\n","def Sigmoid(x) :\n","    return tf.nn.sigmoid(x)\n","\n","def Concatenation(layers) :\n","    return tf.concat(layers, axis=3)\n","\n","def Fully_connected(x, units=class_num, layer_name='fully_connected') :\n","    with tf.name_scope(layer_name) :\n","        return tf.layers.dense(inputs=x, use_bias=False, units=units)\n","\n","def Evaluate(sess):\n","    test_acc = 0.0\n","    test_loss = 0.0\n","    test_pre_index = 0\n","    add = int(len(test_x)/test_iteration)\n","\n","    for it in range(test_iteration):\n","        test_batch_x = test_x[test_pre_index: test_pre_index + add]\n","        test_batch_y = test_y[test_pre_index: test_pre_index + add]\n","        test_pre_index = test_pre_index + add\n","\n","        test_feed_dict = {\n","            x: test_batch_x,\n","            label: test_batch_y,\n","            learning_rate: epoch_learning_rate,\n","            training_flag: False\n","        }\n","\n","        loss_, acc_ = sess.run([cost, accuracy], feed_dict=test_feed_dict)\n","\n","        test_loss += loss_\n","        test_acc += acc_\n","\n","    test_loss /= test_iteration # average loss\n","    test_acc /= test_iteration # average accuracy\n","\n","    summary = tf.Summary(value=[tf.Summary.Value(tag='test_loss', simple_value=test_loss),\n","                                tf.Summary.Value(tag='test_accuracy', simple_value=test_acc)])\n","\n","    return test_acc, test_loss, summary\n","\n","class SE_ResNeXt():\n","    def __init__(self, x, training):\n","        self.training = training\n","        self.model = self.Build_SEnet(x)\n","\n","    def first_layer(self, x, scope):\n","        with tf.name_scope(scope) :\n","            x = conv_layer(x, filter=64, kernel=[3, 3], stride=1, layer_name=scope+'_conv1')\n","            x = Batch_Normalization(x, training=self.training, scope=scope+'_batch1')\n","            x = Relu(x)\n","\n","            return x\n","\n","    def transform_layer(self, x, stride, scope):\n","        with tf.name_scope(scope) :\n","            x = conv_layer(x, filter=depth, kernel=[1,1], stride=1, layer_name=scope+'_conv1')\n","            x = Batch_Normalization(x, training=self.training, scope=scope+'_batch1')\n","            x = Relu(x)\n","\n","            x = conv_layer(x, filter=depth, kernel=[3,3], stride=stride, layer_name=scope+'_conv2')\n","            x = Batch_Normalization(x, training=self.training, scope=scope+'_batch2')\n","            x = Relu(x)\n","            return x\n","\n","    def transition_layer(self, x, out_dim, scope):\n","        with tf.name_scope(scope):\n","            x = conv_layer(x, filter=out_dim, kernel=[1,1], stride=1, layer_name=scope+'_conv1')\n","            x = Batch_Normalization(x, training=self.training, scope=scope+'_batch1')\n","            # x = Relu(x)\n","\n","            return x\n","\n","    def split_layer(self, input_x, stride, layer_name):\n","        with tf.name_scope(layer_name) :\n","            layers_split = list()\n","            for i in range(cardinality) :\n","                splits = self.transform_layer(input_x, stride=stride, scope=layer_name + '_splitN_' + str(i))\n","                layers_split.append(splits)\n","\n","            return Concatenation(layers_split)\n","\n","    def squeeze_excitation_layer(self, input_x, out_dim, ratio, layer_name):\n","        with tf.name_scope(layer_name) :\n","\n","\n","            squeeze = Global_Average_Pooling(input_x)\n","\n","            excitation = Fully_connected(squeeze, units=out_dim / ratio, layer_name=layer_name+'_fully_connected1')\n","            excitation = Relu(excitation)\n","            excitation = Fully_connected(excitation, units=out_dim, layer_name=layer_name+'_fully_connected2')\n","            excitation = Sigmoid(excitation)\n","\n","            excitation = tf.reshape(excitation, [-1,1,1,out_dim])\n","            scale = input_x * excitation\n","\n","            return scale\n","\n","    def residual_layer(self, input_x, out_dim, layer_num, res_block=blocks):\n","        # split + transform(bottleneck) + transition + merge\n","        # input_dim = input_x.get_shape().as_list()[-1]\n","\n","        for i in range(res_block):\n","            input_dim = int(np.shape(input_x)[-1])\n","\n","            if input_dim * 2 == out_dim:\n","                flag = True\n","                stride = 2\n","                channel = input_dim // 2\n","            else:\n","                flag = False\n","                stride = 1\n","\n","            x = self.split_layer(input_x, stride=stride, layer_name='split_layer_'+layer_num+'_'+str(i))\n","            x = self.transition_layer(x, out_dim=out_dim, scope='trans_layer_'+layer_num+'_'+str(i))\n","            x = self.squeeze_excitation_layer(x, out_dim=out_dim, ratio=reduction_ratio, layer_name='squeeze_layer_'+layer_num+'_'+str(i))\n","\n","            if flag is True :\n","                pad_input_x = Average_pooling(input_x)\n","                pad_input_x = tf.pad(pad_input_x, [[0, 0], [0, 0], [0, 0], [channel, channel]]) # [?, height, width, channel]\n","            else :\n","                pad_input_x = input_x\n","\n","            input_x = Relu(x + pad_input_x)\n","\n","        return input_x\n","\n","\n","    def Build_SEnet(self, input_x):\n","        # only cifar10 architecture\n","\n","        input_x = self.first_layer(input_x, scope='first_layer')\n","\n","        x = self.residual_layer(input_x, out_dim=64, layer_num='1')\n","        x = self.residual_layer(x, out_dim=128, layer_num='2')\n","        x = self.residual_layer(x, out_dim=256, layer_num='3')\n","        x = self.residual_layer(x, out_dim=512, layer_num='4')\n","        \n","        x = Global_Average_Pooling(x)\n","        x = flatten(x)\n","\n","        x = Fully_connected(x, layer_name='final_fully_connected')\n","        return x\n","\n","\n","train_x, train_y, test_x, test_y = prepare_data()\n","train_x, test_x = color_preprocessing(train_x, test_x)\n","\n","\n","# image_size = 32, img_channels = 3, class_num = 10 in cifar10\n","x = tf.placeholder(tf.float32, shape=[None, image_size, image_size, img_channels])\n","label = tf.placeholder(tf.float32, shape=[None, class_num])\n","\n","training_flag = tf.placeholder(tf.bool)\n","\n","\n","learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n","\n","logits = SE_ResNeXt(x, training=training_flag).model\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=label, logits=logits))\n","\n","l2_loss = tf.add_n([tf.nn.l2_loss(var) for var in tf.trainable_variables()])\n","optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=momentum, use_nesterov=True)\n","train = optimizer.minimize(cost + l2_loss * weight_decay)\n","\n","correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(label, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","\n","saver = tf.train.Saver(tf.global_variables())\n","\n","# with tf.Session() as sess:\n","with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess :\n","    ckpt = tf.train.get_checkpoint_state('./model_v1_4')\n","    if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n","        saver.restore(sess, ckpt.model_checkpoint_path)\n","    else:\n","        sess.run(tf.global_variables_initializer())\n","\n","    summary_writer = tf.summary.FileWriter('./logs_v1_4', sess.graph)\n","\n","    epoch_learning_rate = init_learning_rate\n","    for epoch in range(1, total_epochs + 1):\n","        if epoch % 30 == 0 :\n","            epoch_learning_rate = epoch_learning_rate / 10\n","\n","        pre_index = 0\n","        train_acc = 0.0\n","        train_loss = 0.0\n","\n","        for step in range(1, iteration + 1):\n","            if pre_index + batch_size < 4586:\n","                batch_x = train_x[pre_index: pre_index + batch_size]\n","                batch_y = train_y[pre_index: pre_index + batch_size]\n","            else:\n","                batch_x = train_x[pre_index:]\n","                batch_y = train_y[pre_index:]\n","\n","            batch_x = data_augmentation(batch_x)\n","\n","            train_feed_dict = {\n","                x: batch_x,\n","                label: batch_y,\n","                learning_rate: epoch_learning_rate,\n","                training_flag: True\n","            }\n","\n","            _, batch_loss = sess.run([train, cost], feed_dict=train_feed_dict)\n","            batch_acc = accuracy.eval(feed_dict=train_feed_dict)\n","\n","            train_loss += batch_loss\n","            train_acc += batch_acc\n","            pre_index += batch_size\n","\n","\n","        train_loss /= iteration # average loss\n","        train_acc /= iteration # average accuracy\n","\n","        train_summary = tf.Summary(value=[tf.Summary.Value(tag='train_loss', simple_value=train_loss),\n","                                          tf.Summary.Value(tag='train_accuracy', simple_value=train_acc)])\n","\n","        test_acc, test_loss, test_summary = Evaluate(sess)\n","\n","        summary_writer.add_summary(summary=train_summary, global_step=epoch)\n","        summary_writer.add_summary(summary=test_summary, global_step=epoch)\n","        summary_writer.flush()\n","\n","        line = \"epoch: %d/%d, train_loss: %.4f, train_acc: %.4f, test_loss: %.4f, test_acc: %.4f \\n\" % (\n","            epoch, total_epochs, train_loss, train_acc, test_loss, test_acc)\n","        print(line)\n","\n","        with open('logs.txt', 'a') as f:\n","            f.write(line)\n","\n","        saver.save(sess=sess, save_path='./model_v1_4/ResNeXt_v1_4.ckpt')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kHcyG705cGtw","colab_type":"text"},"source":["Then, I want to  decrease a residual_layer based on the original model.(v1.5)\n","\n","\n","```\n","# Difference\n","\n","    def Build_SEnet(self, input_x):\n","        # only cifar10 architecture\n","\n","        input_x = self.first_layer(input_x, scope='first_layer')\n","\n","        x = self.residual_layer(input_x, out_dim=64, layer_num='1')\n","        x = self.residual_layer(x, out_dim=128, layer_num='2')\n","\n","        \n","        x = Global_Average_Pooling(x)\n","        x = flatten(x)\n","\n","        x = Fully_connected(x, layer_name='final_fully_connected')\n","        return x\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"ZM0gXuVGcKky","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tflearn.layers.conv import global_avg_pool\n","from tensorflow.contrib.layers import batch_norm, flatten\n","from tensorflow.contrib.framework import arg_scope\n","import keras.layers\n","import numpy as np\n","\n","weight_decay = 0.0005\n","momentum = 0.9\n","\n","init_learning_rate = 0.1\n","cardinality = 8 # how many split ?\n","blocks = 3 # res_block ! (split + transition)\n","depth = 64 # out channel\n","\n","\"\"\"\n","So, the total number of layers is (3*blokcs)*residual_layer_num + 2\n","because, blocks = split(conv 2) + transition(conv 1) = 3 layer\n","and, first conv layer 1, last dense layer 1\n","thus, total number of layers = (3*blocks)*residual_layer_num + 2\n","\"\"\"\n","\n","reduction_ratio = 4\n","class_num=10\n","batch_size = 128\n","\n","# iteration = 391\n","# 128 * 391 ~ 50,000\n","\n","iteration=36\n","# 128*36~4608\n","\n","test_iteration = 10\n","\n","total_epochs = 100\n","\n","def conv_layer(input, filter, kernel, stride, padding='SAME', layer_name=\"conv\"):\n","    with tf.name_scope(layer_name):\n","        network = tf.layers.conv2d(inputs=input, use_bias=False, filters=filter, kernel_size=kernel, strides=stride, padding=padding)\n","        return network\n","\n","def Global_Average_Pooling(x):\n","    return global_avg_pool(x, name='Global_avg_pooling')\n","\n","def Average_pooling(x, pool_size=[2,2], stride=2, padding='SAME'):\n","    return tf.layers.average_pooling2d(inputs=x, pool_size=pool_size, strides=stride, padding=padding)\n","\n","def Batch_Normalization(x, training, scope):\n","    with arg_scope([batch_norm],\n","                   scope=scope,\n","                   updates_collections=None,\n","                   decay=0.9,\n","                   center=True,\n","                   scale=True,\n","                   zero_debias_moving_mean=True) :\n","        return tf.cond(training,\n","                       lambda : batch_norm(inputs=x, is_training=training, reuse=None),\n","                       lambda : batch_norm(inputs=x, is_training=training, reuse=True))\n","\n","def Relu(x):\n","    return tf.nn.relu(x)\n","\n","def Sigmoid(x) :\n","    return tf.nn.sigmoid(x)\n","\n","def Concatenation(layers) :\n","    return tf.concat(layers, axis=3)\n","\n","def Fully_connected(x, units=class_num, layer_name='fully_connected') :\n","    with tf.name_scope(layer_name) :\n","        return tf.layers.dense(inputs=x, use_bias=False, units=units)\n","\n","def Evaluate(sess):\n","    test_acc = 0.0\n","    test_loss = 0.0\n","    test_pre_index = 0\n","    add = int(len(test_x)/test_iteration)\n","\n","    for it in range(test_iteration):\n","        test_batch_x = test_x[test_pre_index: test_pre_index + add]\n","        test_batch_y = test_y[test_pre_index: test_pre_index + add]\n","        test_pre_index = test_pre_index + add\n","\n","        test_feed_dict = {\n","            x: test_batch_x,\n","            label: test_batch_y,\n","            learning_rate: epoch_learning_rate,\n","            training_flag: False\n","        }\n","\n","        loss_, acc_ = sess.run([cost, accuracy], feed_dict=test_feed_dict)\n","\n","        test_loss += loss_\n","        test_acc += acc_\n","\n","    test_loss /= test_iteration # average loss\n","    test_acc /= test_iteration # average accuracy\n","\n","    summary = tf.Summary(value=[tf.Summary.Value(tag='test_loss', simple_value=test_loss),\n","                                tf.Summary.Value(tag='test_accuracy', simple_value=test_acc)])\n","\n","    return test_acc, test_loss, summary\n","\n","class SE_ResNeXt():\n","    def __init__(self, x, training):\n","        self.training = training\n","        self.model = self.Build_SEnet(x)\n","\n","    def first_layer(self, x, scope):\n","        with tf.name_scope(scope) :\n","            x = conv_layer(x, filter=64, kernel=[3, 3], stride=1, layer_name=scope+'_conv1')\n","            x = Batch_Normalization(x, training=self.training, scope=scope+'_batch1')\n","            x = Relu(x)\n","\n","            return x\n","\n","    def transform_layer(self, x, stride, scope):\n","        with tf.name_scope(scope) :\n","            x = conv_layer(x, filter=depth, kernel=[1,1], stride=1, layer_name=scope+'_conv1')\n","            x = Batch_Normalization(x, training=self.training, scope=scope+'_batch1')\n","            x = Relu(x)\n","\n","            x = conv_layer(x, filter=depth, kernel=[3,3], stride=stride, layer_name=scope+'_conv2')\n","            x = Batch_Normalization(x, training=self.training, scope=scope+'_batch2')\n","            x = Relu(x)\n","            return x\n","\n","    def transition_layer(self, x, out_dim, scope):\n","        with tf.name_scope(scope):\n","            x = conv_layer(x, filter=out_dim, kernel=[1,1], stride=1, layer_name=scope+'_conv1')\n","            x = Batch_Normalization(x, training=self.training, scope=scope+'_batch1')\n","            # x = Relu(x)\n","\n","            return x\n","\n","    def split_layer(self, input_x, stride, layer_name):\n","        with tf.name_scope(layer_name) :\n","            layers_split = list()\n","            for i in range(cardinality) :\n","                splits = self.transform_layer(input_x, stride=stride, scope=layer_name + '_splitN_' + str(i))\n","                layers_split.append(splits)\n","\n","            return Concatenation(layers_split)\n","\n","    def squeeze_excitation_layer(self, input_x, out_dim, ratio, layer_name):\n","        with tf.name_scope(layer_name) :\n","\n","\n","            squeeze = Global_Average_Pooling(input_x)\n","\n","            excitation = Fully_connected(squeeze, units=out_dim / ratio, layer_name=layer_name+'_fully_connected1')\n","            excitation = Relu(excitation)\n","            excitation = Fully_connected(excitation, units=out_dim, layer_name=layer_name+'_fully_connected2')\n","            excitation = Sigmoid(excitation)\n","\n","            excitation = tf.reshape(excitation, [-1,1,1,out_dim])\n","            scale = input_x * excitation\n","\n","            return scale\n","\n","    def residual_layer(self, input_x, out_dim, layer_num, res_block=blocks):\n","        # split + transform(bottleneck) + transition + merge\n","        # input_dim = input_x.get_shape().as_list()[-1]\n","\n","        for i in range(res_block):\n","            input_dim = int(np.shape(input_x)[-1])\n","\n","            if input_dim * 2 == out_dim:\n","                flag = True\n","                stride = 2\n","                channel = input_dim // 2\n","            else:\n","                flag = False\n","                stride = 1\n","\n","            x = self.split_layer(input_x, stride=stride, layer_name='split_layer_'+layer_num+'_'+str(i))\n","            x = self.transition_layer(x, out_dim=out_dim, scope='trans_layer_'+layer_num+'_'+str(i))\n","            x = self.squeeze_excitation_layer(x, out_dim=out_dim, ratio=reduction_ratio, layer_name='squeeze_layer_'+layer_num+'_'+str(i))\n","\n","            if flag is True :\n","                pad_input_x = Average_pooling(input_x)\n","                pad_input_x = tf.pad(pad_input_x, [[0, 0], [0, 0], [0, 0], [channel, channel]]) # [?, height, width, channel]\n","            else :\n","                pad_input_x = input_x\n","\n","            input_x = Relu(x + pad_input_x)\n","\n","        return input_x\n","\n","\n","    def Build_SEnet(self, input_x):\n","        # only cifar10 architecture\n","\n","        input_x = self.first_layer(input_x, scope='first_layer')\n","\n","        x = self.residual_layer(input_x, out_dim=64, layer_num='1')\n","        x = self.residual_layer(x, out_dim=128, layer_num='2')\n","\n","\n","        x = Global_Average_Pooling(x)\n","        x = flatten(x)\n","\n","        x = Fully_connected(x, layer_name='final_fully_connected')\n","        return x\n","\n","\n","train_x, train_y, test_x, test_y = prepare_data()\n","train_x, test_x = color_preprocessing(train_x, test_x)\n","\n","\n","# image_size = 32, img_channels = 3, class_num = 10 in cifar10\n","x = tf.placeholder(tf.float32, shape=[None, image_size, image_size, img_channels])\n","label = tf.placeholder(tf.float32, shape=[None, class_num])\n","\n","training_flag = tf.placeholder(tf.bool)\n","\n","\n","learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n","\n","logits = SE_ResNeXt(x, training=training_flag).model\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=label, logits=logits))\n","\n","l2_loss = tf.add_n([tf.nn.l2_loss(var) for var in tf.trainable_variables()])\n","optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=momentum, use_nesterov=True)\n","train = optimizer.minimize(cost + l2_loss * weight_decay)\n","\n","correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(label, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","\n","saver = tf.train.Saver(tf.global_variables())\n","\n","# with tf.Session() as sess:\n","with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess :\n","    ckpt = tf.train.get_checkpoint_state('./model_v1_5')\n","    if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n","        saver.restore(sess, ckpt.model_checkpoint_path)\n","    else:\n","        sess.run(tf.global_variables_initializer())\n","\n","    summary_writer = tf.summary.FileWriter('./logs_v1_5', sess.graph)\n","\n","    epoch_learning_rate = init_learning_rate\n","    for epoch in range(1, total_epochs + 1):\n","        if epoch % 30 == 0 :\n","            epoch_learning_rate = epoch_learning_rate / 10\n","\n","        pre_index = 0\n","        train_acc = 0.0\n","        train_loss = 0.0\n","\n","        for step in range(1, iteration + 1):\n","            if pre_index + batch_size < 4586:\n","                batch_x = train_x[pre_index: pre_index + batch_size]\n","                batch_y = train_y[pre_index: pre_index + batch_size]\n","            else:\n","                batch_x = train_x[pre_index:]\n","                batch_y = train_y[pre_index:]\n","\n","            batch_x = data_augmentation(batch_x)\n","\n","            train_feed_dict = {\n","                x: batch_x,\n","                label: batch_y,\n","                learning_rate: epoch_learning_rate,\n","                training_flag: True\n","            }\n","\n","            _, batch_loss = sess.run([train, cost], feed_dict=train_feed_dict)\n","            batch_acc = accuracy.eval(feed_dict=train_feed_dict)\n","\n","            train_loss += batch_loss\n","            train_acc += batch_acc\n","            pre_index += batch_size\n","\n","\n","        train_loss /= iteration # average loss\n","        train_acc /= iteration # average accuracy\n","\n","        train_summary = tf.Summary(value=[tf.Summary.Value(tag='train_loss', simple_value=train_loss),\n","                                          tf.Summary.Value(tag='train_accuracy', simple_value=train_acc)])\n","\n","        test_acc, test_loss, test_summary = Evaluate(sess)\n","\n","        summary_writer.add_summary(summary=train_summary, global_step=epoch)\n","        summary_writer.add_summary(summary=test_summary, global_step=epoch)\n","        summary_writer.flush()\n","\n","        line = \"epoch: %d/%d, train_loss: %.4f, train_acc: %.4f, test_loss: %.4f, test_acc: %.4f \\n\" % (\n","            epoch, total_epochs, train_loss, train_acc, test_loss, test_acc)\n","        print(line)\n","\n","        with open('logs.txt', 'a') as f:\n","            f.write(line)\n","\n","        saver.save(sess=sess, save_path='./model_v1_5/ResNeXt_v1_5.ckpt')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XKfUXzcKcOwv","colab_type":"text"},"source":["The following cell is to compress the model we trained."]},{"cell_type":"code","metadata":{"id":"7sWI4Oa1nIxH","colab_type":"code","colab":{}},"source":["!zip -r ResNeXt_model.zip model\n","!ls -l"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r46M76RsnMfM","colab_type":"code","colab":{}},"source":["!zip -r ResNeXt_model_v1_4.zip model_v1_4\n","!ls -l"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-pISi3LJnOvw","colab_type":"code","colab":{}},"source":["!zip -r ResNeXt_model_v1_5.zip model_v1_5\n","!ls -l"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YEORbys-k9NM","colab_type":"text"},"source":["The following cell is to upload the model to Google Drive.\n","\n"]},{"cell_type":"code","metadata":{"id":"gjCfXr6BnaK-","colab_type":"code","colab":{}},"source":["# Install the PyDrive wrapper & import libraries.\n","# This only needs to be done once in a notebook.\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once in a notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# Create & upload a text file.\n","uploaded = drive.CreateFile()\n","uploaded.SetContentFile('ResNeXt_model.zip')\n","uploaded.Upload()\n","print('Uploaded file with ID {}'.format(uploaded.get('id')))\n","# Uploaded file with ID 1zDwXJxuLPkODAG99Yvd7VLCqihPTKkUS"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"izctAQRdncTp","colab_type":"code","colab":{}},"source":["# Install the PyDrive wrapper & import libraries.\n","# This only needs to be done once in a notebook.\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once in a notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# Create & upload a text file.\n","uploaded = drive.CreateFile()\n","uploaded.SetContentFile('ResNeXt_model_v1_4.zip')\n","uploaded.Upload()\n","print('Uploaded file with ID {}'.format(uploaded.get('id')))\n","Uploaded file with ID 1nIywPp_ud3DV5J7LVbFxvYjqlovoPES-"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmZ9gNwxneaB","colab_type":"code","colab":{}},"source":["# Install the PyDrive wrapper & import libraries.\n","# This only needs to be done once in a notebook.\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once in a notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# Create & upload a text file.\n","uploaded = drive.CreateFile()\n","uploaded.SetContentFile('ResNeXt_model_v1_5.zip')\n","uploaded.Upload()\n","print('Uploaded file with ID {}'.format(uploaded.get('id')))\n","# Uploaded file with ID 1R-ZXjd1Mixuk3aHFCMpqPhpwyT_lVFOj\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uvLjZtBCjFpf","colab_type":"text"},"source":["Finally, we should upload one picture to get the prediction. You should download the model and choose the right cell for different version."]},{"cell_type":"markdown","metadata":{"id":"PHQvdXLwjxST","colab_type":"text"},"source":["To start our prediction, you should run the following cell first."]},{"cell_type":"code","metadata":{"id":"59srbN4ZkHFz","colab_type":"code","colab":{}},"source":["import numpy as np\n","import cv2 as cv\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder\n","import os\n","from PIL import Image\n","import random\n","\n","class_num = 10\n","image_size = 32\n","img_channels = 3\n","\n","\n","def rgb_normalization(filename):\n","\tgifimg = Image.open(filename)\n","\tif (gifimg.mode != \"RGB\"):\n","\t\tgifimg = gifimg.convert('RGB')\n","\tout=gifimg.resize((32, 32), Image.ANTIALIAS)\n","\tname = filename[:-4] + '_pred.jpg'\n","\tout.save(name)\n","\treturn name\n","\n","\n","def get_rgb_vector(imgPath):\n","\timg = cv.imread(imgPath)\n","\t# img=cv.resize(img,(32,32))\n","\tB, G, R = cv.split(img)\n","\tB = np.reshape(B, (1, 1024))\n","\tG = np.reshape(G, (1, 1024))\n","\tR = np.reshape(R, (1, 1024))\n","\tvector = np.concatenate((R, G, B), axis=1)\n","\treturn vector\n","\n","\n","def prepare_data(imgPath):\n","\timgPath=rgb_normalization(imgPath)\n","\tdata = []\n","\timg=cv.imread(imgPath)\n","\tdata.append(img)\n","\tdata = np.array(data)\n","\treturn data\n","\n","\n","def _random_crop(batch, crop_shape, padding=None):\n","\toshape = np.shape(batch[0])\n","\n","\tif padding:\n","\t\toshape = (oshape[0] + 2 * padding, oshape[1] + 2 * padding)\n","\tnew_batch = []\n","\tnpad = ((padding, padding), (padding, padding), (0, 0))\n","\tfor i in range(len(batch)):\n","\t\tnew_batch.append(batch[i])\n","\t\tif padding:\n","\t\t\tnew_batch[i] = np.lib.pad(batch[i], pad_width=npad,\n","\t\t\t                          mode='constant', constant_values=0)\n","\t\tnh = random.randint(0, oshape[0] - crop_shape[0])\n","\t\tnw = random.randint(0, oshape[1] - crop_shape[1])\n","\t\tnew_batch[i] = new_batch[i][nh:nh + crop_shape[0],\n","\t\t               nw:nw + crop_shape[1]]\n","\treturn new_batch\n","\n","\n","def _random_flip_leftright(batch):\n","\tfor i in range(len(batch)):\n","\t\tif bool(random.getrandbits(1)):\n","\t\t\tbatch[i] = np.fliplr(batch[i])\n","\treturn batch\n","\n","\n","def color_preprocessing(x):\n","\tx = x.astype('float32')\n","\tx[:, :, :, 0] = (x[:, :, :, 0] - np.mean(x[:, :, :, 0])) / np.std(x[:, :, :, 0])\n","\tx[:, :, :, 1] = (x[:, :, :, 1] - np.mean(x[:, :, :, 1])) / np.std(x[:, :, :, 1])\n","\tx[:, :, :, 2] = (x[:, :, :, 2] - np.mean(x[:, :, :, 2])) / np.std(x[:, :, :, 2])\n","\n","\treturn x\n","\n","\n","def data_augmentation(batch):\n","\tbatch = _random_flip_leftright(batch)\n","\tbatch = _random_crop(batch, [32, 32], 4)\n","\treturn batch\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I0zJNNOHkyNA","colab_type":"text"},"source":["Then, you should download a test picture. If its name isn't 'test_img.jpg', please rename it."]},{"cell_type":"code","metadata":{"id":"kkoLD0Rwl5Zu","colab_type":"code","colab":{}},"source":["!wget https://github.com/xuhk0220/Emoji_Classification/raw/master/test_img.jpg"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a7-Li-cdykkN","colab_type":"text"},"source":["We can have a look first."]},{"cell_type":"code","metadata":{"id":"8h337L0Myprc","colab_type":"code","outputId":"5d9167a0-a922-4066-f34c-466455b7cc79","executionInfo":{"status":"ok","timestamp":1561473825229,"user_tz":-480,"elapsed":2639,"user":{"displayName":"俊鸿吴","photoUrl":"","userId":"12931897950753340475"}},"colab":{"base_uri":"https://localhost:8080/","height":257}},"source":["from google.colab.patches import cv2_imshow\n","import cv2 as cv\n","predict_imgPath = './test_img.jpg'\n","img = cv.imread(predict_imgPath)\n","cv2_imshow(img)\n","# fig = plt.figure()\n","# plt.imshow(img)\n","# fig.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPAAAADwCAIAAACxN37FAACfeklEQVR4nO1dd3wVVfa/M/N6Tw9J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\nQioAAAAASUVORK5CYII=\n","text/plain":["<PIL.Image.Image image mode=RGB size=240x240 at 0x7F069A5B1208>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"0cngZKvCy7pP","colab_type":"text"},"source":["Then we can output the prediction of the picture."]},{"cell_type":"markdown","metadata":{"id":"Ztd6_B-ZzDfz","colab_type":"text"},"source":["Prediction code for v1.3"]},{"cell_type":"code","metadata":{"id":"0Ivl5CZdzMiW","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tflearn.layers.conv import global_avg_pool\n","from tensorflow.contrib.layers import batch_norm, flatten\n","from tensorflow.contrib.framework import arg_scope\n","import keras.layers\n","import numpy as np\n","\n","weight_decay = 0.0005\n","momentum = 0.9\n","\n","init_learning_rate = 0.1\n","\n","cardinality = 8  # how many split ?\n","blocks = 3  # res_block ! (split + transition)\n","depth = 64  # out channel\n","\n","\"\"\"\n","So, the total number of layers is (3*blokcs)*residual_layer_num + 2\n","because, blocks = split(conv 2) + transition(conv 1) = 3 layer\n","and, first conv layer 1, last dense layer 1\n","thus, total number of layers = (3*blocks)*residual_layer_num + 2\n","\"\"\"\n","prediction_dict = ['小猪佩奇', '蘑菇头', '可爱柴犬', '猥琐猫', '猫', '笑', '熊本熊', '熊猫头', '文字', '长草颜']\n","reduction_ratio = 4\n","class_num = 10\n","batch_size = 1\n","\n","# iteration = 391\n","# 128 * 391 ~ 50,000\n","\n","iteration = 1\n","# 1*1~1\n","\n","test_iteration = 10\n","\n","total_epochs = 100\n","\n","\n","def conv_layer(input, filter, kernel, stride, padding='SAME', layer_name=\"conv\"):\n","\twith tf.name_scope(layer_name):\n","\t\tnetwork = tf.layers.conv2d(inputs=input, use_bias=False, filters=filter, kernel_size=kernel, strides=stride,\n","\t\t                           padding=padding)\n","\t\treturn network\n","\n","\n","def Global_Average_Pooling(x):\n","\treturn global_avg_pool(x, name='Global_avg_pooling')\n","\n","\n","def Average_pooling(x, pool_size=[2, 2], stride=2, padding='SAME'):\n","\treturn tf.layers.average_pooling2d(inputs=x, pool_size=pool_size, strides=stride, padding=padding)\n","\n","\n","def Batch_Normalization(x, training, scope):\n","\twith arg_scope([batch_norm],\n","\t               scope=scope,\n","\t               updates_collections=None,\n","\t               decay=0.9,\n","\t               center=True,\n","\t               scale=True,\n","\t               zero_debias_moving_mean=True):\n","\t\treturn tf.cond(training,\n","\t\t               lambda: batch_norm(inputs=x, is_training=training, reuse=None),\n","\t\t               lambda: batch_norm(inputs=x, is_training=training, reuse=True))\n","\n","\n","def Relu(x):\n","\treturn tf.nn.relu(x)\n","\n","\n","def Sigmoid(x):\n","\treturn tf.nn.sigmoid(x)\n","\n","\n","def Concatenation(layers):\n","\treturn tf.concat(layers, axis=3)\n","\n","\n","def Fully_connected(x, units=class_num, layer_name='fully_connected'):\n","\twith tf.name_scope(layer_name):\n","\t\treturn tf.layers.dense(inputs=x, use_bias=False, units=units)\n","\n","\n","class SE_ResNeXt():\n","\tdef __init__(self, x, training):\n","\t\tself.training = training\n","\t\tself.model = self.Build_SEnet(x)\n","\n","\tdef first_layer(self, x, scope):\n","\t\twith tf.name_scope(scope):\n","\t\t\tx = conv_layer(x, filter=64, kernel=[3, 3], stride=1, layer_name=scope + '_conv1')\n","\t\t\tx = Batch_Normalization(x, training=self.training, scope=scope + '_batch1')\n","\t\t\tx = Relu(x)\n","\n","\t\t\treturn x\n","\n","\tdef transform_layer(self, x, stride, scope):\n","\t\twith tf.name_scope(scope):\n","\t\t\tx = conv_layer(x, filter=depth, kernel=[1, 1], stride=1, layer_name=scope + '_conv1')\n","\t\t\tx = Batch_Normalization(x, training=self.training, scope=scope + '_batch1')\n","\t\t\tx = Relu(x)\n","\n","\t\t\tx = conv_layer(x, filter=depth, kernel=[3, 3], stride=stride, layer_name=scope + '_conv2')\n","\t\t\tx = Batch_Normalization(x, training=self.training, scope=scope + '_batch2')\n","\t\t\tx = Relu(x)\n","\t\t\treturn x\n","\n","\tdef transition_layer(self, x, out_dim, scope):\n","\t\twith tf.name_scope(scope):\n","\t\t\tx = conv_layer(x, filter=out_dim, kernel=[1, 1], stride=1, layer_name=scope + '_conv1')\n","\t\t\tx = Batch_Normalization(x, training=self.training, scope=scope + '_batch1')\n","\t\t\t# x = Relu(x)\n","\n","\t\t\treturn x\n","\n","\tdef split_layer(self, input_x, stride, layer_name):\n","\t\twith tf.name_scope(layer_name):\n","\t\t\tlayers_split = list()\n","\t\t\tfor i in range(cardinality):\n","\t\t\t\tsplits = self.transform_layer(input_x, stride=stride, scope=layer_name + '_splitN_' + str(i))\n","\t\t\t\tlayers_split.append(splits)\n","\n","\t\t\treturn Concatenation(layers_split)\n","\n","\tdef squeeze_excitation_layer(self, input_x, out_dim, ratio, layer_name):\n","\t\twith tf.name_scope(layer_name):\n","\t\t\tsqueeze = Global_Average_Pooling(input_x)\n","\n","\t\t\texcitation = Fully_connected(squeeze, units=out_dim / ratio, layer_name=layer_name + '_fully_connected1')\n","\t\t\texcitation = Relu(excitation)\n","\t\t\texcitation = Fully_connected(excitation, units=out_dim, layer_name=layer_name + '_fully_connected2')\n","\t\t\texcitation = Sigmoid(excitation)\n","\n","\t\t\texcitation = tf.reshape(excitation, [-1, 1, 1, out_dim])\n","\t\t\tscale = input_x * excitation\n","\n","\t\t\treturn scale\n","\n","\tdef residual_layer(self, input_x, out_dim, layer_num, res_block=blocks):\n","\t\t# split + transform(bottleneck) + transition + merge\n","\t\t# input_dim = input_x.get_shape().as_list()[-1]\n","\n","\t\tfor i in range(res_block):\n","\t\t\tinput_dim = int(np.shape(input_x)[-1])\n","\n","\t\t\tif input_dim * 2 == out_dim:\n","\t\t\t\tflag = True\n","\t\t\t\tstride = 2\n","\t\t\t\tchannel = input_dim // 2\n","\t\t\telse:\n","\t\t\t\tflag = False\n","\t\t\t\tstride = 1\n","\n","\t\t\tx = self.split_layer(input_x, stride=stride, layer_name='split_layer_' + layer_num + '_' + str(i))\n","\t\t\tx = self.transition_layer(x, out_dim=out_dim, scope='trans_layer_' + layer_num + '_' + str(i))\n","\t\t\tx = self.squeeze_excitation_layer(x, out_dim=out_dim, ratio=reduction_ratio,\n","\t\t\t                                  layer_name='squeeze_layer_' + layer_num + '_' + str(i))\n","\n","\t\t\tif flag is True:\n","\t\t\t\tpad_input_x = Average_pooling(input_x)\n","\t\t\t\tpad_input_x = tf.pad(pad_input_x,\n","\t\t\t\t                     [[0, 0], [0, 0], [0, 0], [channel, channel]])  # [?, height, width, channel]\n","\t\t\telse:\n","\t\t\t\tpad_input_x = input_x\n","\n","\t\t\tinput_x = Relu(x + pad_input_x)\n","\n","\t\treturn input_x\n","\n","\tdef Build_SEnet(self, input_x):\n","\t\t# only cifar10 architecture\n","\n","\t\tinput_x = self.first_layer(input_x, scope='first_layer')\n","\n","\t\tx = self.residual_layer(input_x, out_dim=64, layer_num='1')\n","\t\tx = self.residual_layer(x, out_dim=128, layer_num='2')\n","\t\tx = self.residual_layer(x, out_dim=256, layer_num='3')\n","\n","\t\tx = Global_Average_Pooling(x)\n","\t\tx = flatten(x)\n","\n","\t\tx = Fully_connected(x, layer_name='final_fully_connected')\n","\t\treturn x\n","\n","\n","predict_x = prepare_data(predict_imgPath)\n","predict_x = color_preprocessing(predict_x)\n","\n","# image_size = 32, img_channels = 3, class_num = 10 in cifar10\n","x = tf.placeholder(tf.float32, shape=[None, image_size, image_size, img_channels])\n","label = tf.placeholder(tf.float32, shape=[None, class_num])\n","\n","training_flag = tf.placeholder(tf.bool)\n","\n","learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n","\n","logits = SE_ResNeXt(x, training=training_flag).model\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=label, logits=logits))\n","\n","l2_loss = tf.add_n([tf.nn.l2_loss(var) for var in tf.trainable_variables()])\n","optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=momentum, use_nesterov=True)\n","train = optimizer.minimize(cost + l2_loss * weight_decay)\n","\n","correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(label, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","\n","saver = tf.train.Saver(tf.global_variables())\n","predict_x = data_augmentation(predict_x)\n","x_feed_dict = {\n","\tx: predict_x,\n","\ttraining_flag: False\n","}\n","with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n","\tckpt = tf.train.get_checkpoint_state('./model')\n","\tif ckpt and ckpt.model_checkpoint_path:\n","\t\tglobal_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n","\t\tsaver.restore(sess, ckpt.model_checkpoint_path)\n","\t\tprint('Loading success')\n","\telse:\n","\t\tprint('No checkpoint')\n","\tprediction = sess.run(logits, feed_dict=x_feed_dict)\n","max_index = np.argmax(prediction)\n","result = prediction_dict[max_index]\n","print(result)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SGPiCEUXzdJL","colab_type":"text"},"source":["Prediction code for v1.4"]},{"cell_type":"code","metadata":{"id":"V7nqokCYzcEL","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tflearn.layers.conv import global_avg_pool\n","from tensorflow.contrib.layers import batch_norm, flatten\n","from tensorflow.contrib.framework import arg_scope\n","import keras.layers\n","import numpy as np\n","\n","weight_decay = 0.0005\n","momentum = 0.9\n","\n","init_learning_rate = 0.1\n","\n","cardinality = 8  # how many split ?\n","blocks = 3  # res_block ! (split + transition)\n","depth = 64  # out channel\n","\n","\"\"\"\n","So, the total number of layers is (3*blokcs)*residual_layer_num + 2\n","because, blocks = split(conv 2) + transition(conv 1) = 3 layer\n","and, first conv layer 1, last dense layer 1\n","thus, total number of layers = (3*blocks)*residual_layer_num + 2\n","\"\"\"\n","prediction_dict = ['小猪佩奇', '蘑菇头', '可爱柴犬', '猥琐猫', '猫', '笑', '熊本熊', '熊猫头', '文字', '长草颜']\n","reduction_ratio = 4\n","class_num = 10\n","batch_size = 1\n","\n","# iteration = 391\n","# 128 * 391 ~ 50,000\n","\n","iteration = 1\n","# 1*1~1\n","\n","test_iteration = 10\n","\n","total_epochs = 100\n","\n","\n","def conv_layer(input, filter, kernel, stride, padding='SAME', layer_name=\"conv\"):\n","\twith tf.name_scope(layer_name):\n","\t\tnetwork = tf.layers.conv2d(inputs=input, use_bias=False, filters=filter, kernel_size=kernel, strides=stride,\n","\t\t                           padding=padding)\n","\t\treturn network\n","\n","\n","def Global_Average_Pooling(x):\n","\treturn global_avg_pool(x, name='Global_avg_pooling')\n","\n","\n","def Average_pooling(x, pool_size=[2, 2], stride=2, padding='SAME'):\n","\treturn tf.layers.average_pooling2d(inputs=x, pool_size=pool_size, strides=stride, padding=padding)\n","\n","\n","def Batch_Normalization(x, training, scope):\n","\twith arg_scope([batch_norm],\n","\t               scope=scope,\n","\t               updates_collections=None,\n","\t               decay=0.9,\n","\t               center=True,\n","\t               scale=True,\n","\t               zero_debias_moving_mean=True):\n","\t\treturn tf.cond(training,\n","\t\t               lambda: batch_norm(inputs=x, is_training=training, reuse=None),\n","\t\t               lambda: batch_norm(inputs=x, is_training=training, reuse=True))\n","\n","\n","def Relu(x):\n","\treturn tf.nn.relu(x)\n","\n","\n","def Sigmoid(x):\n","\treturn tf.nn.sigmoid(x)\n","\n","\n","def Concatenation(layers):\n","\treturn tf.concat(layers, axis=3)\n","\n","\n","def Fully_connected(x, units=class_num, layer_name='fully_connected'):\n","\twith tf.name_scope(layer_name):\n","\t\treturn tf.layers.dense(inputs=x, use_bias=False, units=units)\n","\n","\n","class SE_ResNeXt():\n","\tdef __init__(self, x, training):\n","\t\tself.training = training\n","\t\tself.model = self.Build_SEnet(x)\n","\n","\tdef first_layer(self, x, scope):\n","\t\twith tf.name_scope(scope):\n","\t\t\tx = conv_layer(x, filter=64, kernel=[3, 3], stride=1, layer_name=scope + '_conv1')\n","\t\t\tx = Batch_Normalization(x, training=self.training, scope=scope + '_batch1')\n","\t\t\tx = Relu(x)\n","\n","\t\t\treturn x\n","\n","\tdef transform_layer(self, x, stride, scope):\n","\t\twith tf.name_scope(scope):\n","\t\t\tx = conv_layer(x, filter=depth, kernel=[1, 1], stride=1, layer_name=scope + '_conv1')\n","\t\t\tx = Batch_Normalization(x, training=self.training, scope=scope + '_batch1')\n","\t\t\tx = Relu(x)\n","\n","\t\t\tx = conv_layer(x, filter=depth, kernel=[3, 3], stride=stride, layer_name=scope + '_conv2')\n","\t\t\tx = Batch_Normalization(x, training=self.training, scope=scope + '_batch2')\n","\t\t\tx = Relu(x)\n","\t\t\treturn x\n","\n","\tdef transition_layer(self, x, out_dim, scope):\n","\t\twith tf.name_scope(scope):\n","\t\t\tx = conv_layer(x, filter=out_dim, kernel=[1, 1], stride=1, layer_name=scope + '_conv1')\n","\t\t\tx = Batch_Normalization(x, training=self.training, scope=scope + '_batch1')\n","\t\t\t# x = Relu(x)\n","\n","\t\t\treturn x\n","\n","\tdef split_layer(self, input_x, stride, layer_name):\n","\t\twith tf.name_scope(layer_name):\n","\t\t\tlayers_split = list()\n","\t\t\tfor i in range(cardinality):\n","\t\t\t\tsplits = self.transform_layer(input_x, stride=stride, scope=layer_name + '_splitN_' + str(i))\n","\t\t\t\tlayers_split.append(splits)\n","\n","\t\t\treturn Concatenation(layers_split)\n","\n","\tdef squeeze_excitation_layer(self, input_x, out_dim, ratio, layer_name):\n","\t\twith tf.name_scope(layer_name):\n","\t\t\tsqueeze = Global_Average_Pooling(input_x)\n","\n","\t\t\texcitation = Fully_connected(squeeze, units=out_dim / ratio, layer_name=layer_name + '_fully_connected1')\n","\t\t\texcitation = Relu(excitation)\n","\t\t\texcitation = Fully_connected(excitation, units=out_dim, layer_name=layer_name + '_fully_connected2')\n","\t\t\texcitation = Sigmoid(excitation)\n","\n","\t\t\texcitation = tf.reshape(excitation, [-1, 1, 1, out_dim])\n","\t\t\tscale = input_x * excitation\n","\n","\t\t\treturn scale\n","\n","\tdef residual_layer(self, input_x, out_dim, layer_num, res_block=blocks):\n","\t\t# split + transform(bottleneck) + transition + merge\n","\t\t# input_dim = input_x.get_shape().as_list()[-1]\n","\n","\t\tfor i in range(res_block):\n","\t\t\tinput_dim = int(np.shape(input_x)[-1])\n","\n","\t\t\tif input_dim * 2 == out_dim:\n","\t\t\t\tflag = True\n","\t\t\t\tstride = 2\n","\t\t\t\tchannel = input_dim // 2\n","\t\t\telse:\n","\t\t\t\tflag = False\n","\t\t\t\tstride = 1\n","\n","\t\t\tx = self.split_layer(input_x, stride=stride, layer_name='split_layer_' + layer_num + '_' + str(i))\n","\t\t\tx = self.transition_layer(x, out_dim=out_dim, scope='trans_layer_' + layer_num + '_' + str(i))\n","\t\t\tx = self.squeeze_excitation_layer(x, out_dim=out_dim, ratio=reduction_ratio,\n","\t\t\t                                  layer_name='squeeze_layer_' + layer_num + '_' + str(i))\n","\n","\t\t\tif flag is True:\n","\t\t\t\tpad_input_x = Average_pooling(input_x)\n","\t\t\t\tpad_input_x = tf.pad(pad_input_x,\n","\t\t\t\t                     [[0, 0], [0, 0], [0, 0], [channel, channel]])  # [?, height, width, channel]\n","\t\t\telse:\n","\t\t\t\tpad_input_x = input_x\n","\n","\t\t\tinput_x = Relu(x + pad_input_x)\n","\n","\t\treturn input_x\n","\n","\tdef Build_SEnet(self, input_x):\n","\t\t# only cifar10 architecture\n","\n","\t\tinput_x = self.first_layer(input_x, scope='first_layer')\n","\n","\t\tx = self.residual_layer(input_x, out_dim=64, layer_num='1')\n","\t\tx = self.residual_layer(x, out_dim=128, layer_num='2')\n","\t\tx = self.residual_layer(x, out_dim=256, layer_num='3')\n","    x = self.residual_layer(x, out_dim=512, layer_num='4')\n","\n","\t\tx = Global_Average_Pooling(x)\n","\t\tx = flatten(x)\n","\n","\t\tx = Fully_connected(x, layer_name='final_fully_connected')\n","\t\treturn x\n","\n","\n","predict_x = prepare_data(predict_imgPath)\n","predict_x = color_preprocessing(predict_x)\n","\n","# image_size = 32, img_channels = 3, class_num = 10 in cifar10\n","x = tf.placeholder(tf.float32, shape=[None, image_size, image_size, img_channels])\n","label = tf.placeholder(tf.float32, shape=[None, class_num])\n","\n","training_flag = tf.placeholder(tf.bool)\n","\n","learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n","\n","logits = SE_ResNeXt(x, training=training_flag).model\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=label, logits=logits))\n","\n","l2_loss = tf.add_n([tf.nn.l2_loss(var) for var in tf.trainable_variables()])\n","optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=momentum, use_nesterov=True)\n","train = optimizer.minimize(cost + l2_loss * weight_decay)\n","\n","correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(label, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","\n","saver = tf.train.Saver(tf.global_variables())\n","predict_x = data_augmentation(predict_x)\n","x_feed_dict = {\n","\tx: predict_x,\n","\ttraining_flag: False\n","}\n","with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n","\tckpt = tf.train.get_checkpoint_state('./model')\n","\tif ckpt and ckpt.model_checkpoint_path:\n","\t\tglobal_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n","\t\tsaver.restore(sess, ckpt.model_checkpoint_path)\n","\t\tprint('Loading success')\n","\telse:\n","\t\tprint('No checkpoint')\n","\tprediction = sess.run(logits, feed_dict=x_feed_dict)\n","max_index = np.argmax(prediction)\n","result = prediction_dict[max_index]\n","print(result)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w0oNGY0Izk5a","colab_type":"text"},"source":["Prediction code for v1.5"]},{"cell_type":"code","metadata":{"id":"QqV_xFzU0UQm","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tflearn.layers.conv import global_avg_pool\n","from tensorflow.contrib.layers import batch_norm, flatten\n","from tensorflow.contrib.framework import arg_scope\n","import keras.layers\n","import numpy as np\n","\n","weight_decay = 0.0005\n","momentum = 0.9\n","\n","init_learning_rate = 0.1\n","\n","cardinality = 8  # how many split ?\n","blocks = 3  # res_block ! (split + transition)\n","depth = 64  # out channel\n","\n","\"\"\"\n","So, the total number of layers is (3*blokcs)*residual_layer_num + 2\n","because, blocks = split(conv 2) + transition(conv 1) = 3 layer\n","and, first conv layer 1, last dense layer 1\n","thus, total number of layers = (3*blocks)*residual_layer_num + 2\n","\"\"\"\n","prediction_dict = ['小猪佩奇', '蘑菇头', '可爱柴犬', '猥琐猫', '猫', '笑', '熊本熊', '熊猫头', '文字', '长草颜']\n","reduction_ratio = 4\n","class_num = 10\n","batch_size = 1\n","\n","# iteration = 391\n","# 128 * 391 ~ 50,000\n","\n","iteration = 1\n","# 1*1~1\n","\n","test_iteration = 10\n","\n","total_epochs = 100\n","\n","\n","def conv_layer(input, filter, kernel, stride, padding='SAME', layer_name=\"conv\"):\n","\twith tf.name_scope(layer_name):\n","\t\tnetwork = tf.layers.conv2d(inputs=input, use_bias=False, filters=filter, kernel_size=kernel, strides=stride,\n","\t\t                           padding=padding)\n","\t\treturn network\n","\n","\n","def Global_Average_Pooling(x):\n","\treturn global_avg_pool(x, name='Global_avg_pooling')\n","\n","\n","def Average_pooling(x, pool_size=[2, 2], stride=2, padding='SAME'):\n","\treturn tf.layers.average_pooling2d(inputs=x, pool_size=pool_size, strides=stride, padding=padding)\n","\n","\n","def Batch_Normalization(x, training, scope):\n","\twith arg_scope([batch_norm],\n","\t               scope=scope,\n","\t               updates_collections=None,\n","\t               decay=0.9,\n","\t               center=True,\n","\t               scale=True,\n","\t               zero_debias_moving_mean=True):\n","\t\treturn tf.cond(training,\n","\t\t               lambda: batch_norm(inputs=x, is_training=training, reuse=None),\n","\t\t               lambda: batch_norm(inputs=x, is_training=training, reuse=True))\n","\n","\n","def Relu(x):\n","\treturn tf.nn.relu(x)\n","\n","\n","def Sigmoid(x):\n","\treturn tf.nn.sigmoid(x)\n","\n","\n","def Concatenation(layers):\n","\treturn tf.concat(layers, axis=3)\n","\n","\n","def Fully_connected(x, units=class_num, layer_name='fully_connected'):\n","\twith tf.name_scope(layer_name):\n","\t\treturn tf.layers.dense(inputs=x, use_bias=False, units=units)\n","\n","\n","class SE_ResNeXt():\n","\tdef __init__(self, x, training):\n","\t\tself.training = training\n","\t\tself.model = self.Build_SEnet(x)\n","\n","\tdef first_layer(self, x, scope):\n","\t\twith tf.name_scope(scope):\n","\t\t\tx = conv_layer(x, filter=64, kernel=[3, 3], stride=1, layer_name=scope + '_conv1')\n","\t\t\tx = Batch_Normalization(x, training=self.training, scope=scope + '_batch1')\n","\t\t\tx = Relu(x)\n","\n","\t\t\treturn x\n","\n","\tdef transform_layer(self, x, stride, scope):\n","\t\twith tf.name_scope(scope):\n","\t\t\tx = conv_layer(x, filter=depth, kernel=[1, 1], stride=1, layer_name=scope + '_conv1')\n","\t\t\tx = Batch_Normalization(x, training=self.training, scope=scope + '_batch1')\n","\t\t\tx = Relu(x)\n","\n","\t\t\tx = conv_layer(x, filter=depth, kernel=[3, 3], stride=stride, layer_name=scope + '_conv2')\n","\t\t\tx = Batch_Normalization(x, training=self.training, scope=scope + '_batch2')\n","\t\t\tx = Relu(x)\n","\t\t\treturn x\n","\n","\tdef transition_layer(self, x, out_dim, scope):\n","\t\twith tf.name_scope(scope):\n","\t\t\tx = conv_layer(x, filter=out_dim, kernel=[1, 1], stride=1, layer_name=scope + '_conv1')\n","\t\t\tx = Batch_Normalization(x, training=self.training, scope=scope + '_batch1')\n","\t\t\t# x = Relu(x)\n","\n","\t\t\treturn x\n","\n","\tdef split_layer(self, input_x, stride, layer_name):\n","\t\twith tf.name_scope(layer_name):\n","\t\t\tlayers_split = list()\n","\t\t\tfor i in range(cardinality):\n","\t\t\t\tsplits = self.transform_layer(input_x, stride=stride, scope=layer_name + '_splitN_' + str(i))\n","\t\t\t\tlayers_split.append(splits)\n","\n","\t\t\treturn Concatenation(layers_split)\n","\n","\tdef squeeze_excitation_layer(self, input_x, out_dim, ratio, layer_name):\n","\t\twith tf.name_scope(layer_name):\n","\t\t\tsqueeze = Global_Average_Pooling(input_x)\n","\n","\t\t\texcitation = Fully_connected(squeeze, units=out_dim / ratio, layer_name=layer_name + '_fully_connected1')\n","\t\t\texcitation = Relu(excitation)\n","\t\t\texcitation = Fully_connected(excitation, units=out_dim, layer_name=layer_name + '_fully_connected2')\n","\t\t\texcitation = Sigmoid(excitation)\n","\n","\t\t\texcitation = tf.reshape(excitation, [-1, 1, 1, out_dim])\n","\t\t\tscale = input_x * excitation\n","\n","\t\t\treturn scale\n","\n","\tdef residual_layer(self, input_x, out_dim, layer_num, res_block=blocks):\n","\t\t# split + transform(bottleneck) + transition + merge\n","\t\t# input_dim = input_x.get_shape().as_list()[-1]\n","\n","\t\tfor i in range(res_block):\n","\t\t\tinput_dim = int(np.shape(input_x)[-1])\n","\n","\t\t\tif input_dim * 2 == out_dim:\n","\t\t\t\tflag = True\n","\t\t\t\tstride = 2\n","\t\t\t\tchannel = input_dim // 2\n","\t\t\telse:\n","\t\t\t\tflag = False\n","\t\t\t\tstride = 1\n","\n","\t\t\tx = self.split_layer(input_x, stride=stride, layer_name='split_layer_' + layer_num + '_' + str(i))\n","\t\t\tx = self.transition_layer(x, out_dim=out_dim, scope='trans_layer_' + layer_num + '_' + str(i))\n","\t\t\tx = self.squeeze_excitation_layer(x, out_dim=out_dim, ratio=reduction_ratio,\n","\t\t\t                                  layer_name='squeeze_layer_' + layer_num + '_' + str(i))\n","\n","\t\t\tif flag is True:\n","\t\t\t\tpad_input_x = Average_pooling(input_x)\n","\t\t\t\tpad_input_x = tf.pad(pad_input_x,\n","\t\t\t\t                     [[0, 0], [0, 0], [0, 0], [channel, channel]])  # [?, height, width, channel]\n","\t\t\telse:\n","\t\t\t\tpad_input_x = input_x\n","\n","\t\t\tinput_x = Relu(x + pad_input_x)\n","\n","\t\treturn input_x\n","\n","\tdef Build_SEnet(self, input_x):\n","\t\t# only cifar10 architecture\n","\n","\t\tinput_x = self.first_layer(input_x, scope='first_layer')\n","\n","\t\tx = self.residual_layer(input_x, out_dim=64, layer_num='1')\n","\t\tx = self.residual_layer(x, out_dim=128, layer_num='2')\n","\n","\t\tx = Global_Average_Pooling(x)\n","\t\tx = flatten(x)\n","\n","\t\tx = Fully_connected(x, layer_name='final_fully_connected')\n","\t\treturn x\n","\n","\n","predict_x = prepare_data(predict_imgPath)\n","predict_x = color_preprocessing(predict_x)\n","\n","# image_size = 32, img_channels = 3, class_num = 10 in cifar10\n","x = tf.placeholder(tf.float32, shape=[None, image_size, image_size, img_channels])\n","label = tf.placeholder(tf.float32, shape=[None, class_num])\n","\n","training_flag = tf.placeholder(tf.bool)\n","\n","learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n","\n","logits = SE_ResNeXt(x, training=training_flag).model\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=label, logits=logits))\n","\n","l2_loss = tf.add_n([tf.nn.l2_loss(var) for var in tf.trainable_variables()])\n","optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=momentum, use_nesterov=True)\n","train = optimizer.minimize(cost + l2_loss * weight_decay)\n","\n","correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(label, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","\n","saver = tf.train.Saver(tf.global_variables())\n","predict_x = data_augmentation(predict_x)\n","x_feed_dict = {\n","\tx: predict_x,\n","\ttraining_flag: False\n","}\n","with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n","\tckpt = tf.train.get_checkpoint_state('./model')\n","\tif ckpt and ckpt.model_checkpoint_path:\n","\t\tglobal_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n","\t\tsaver.restore(sess, ckpt.model_checkpoint_path)\n","\t\tprint('Loading success')\n","\telse:\n","\t\tprint('No checkpoint')\n","\tprediction = sess.run(logits, feed_dict=x_feed_dict)\n","max_index = np.argmax(prediction)\n","result = prediction_dict[max_index]\n","print(result)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"76andkJxmjxU","colab_type":"text"},"source":["The End."]}]}